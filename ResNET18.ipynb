{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am3Ax8IV9SGr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import cv2\n",
        "import pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4Rt901i9i8R"
      },
      "outputs": [],
      "source": [
        "#load_dataset function to load the data and resize the images to 50x50\n",
        "def load_dataset(directory):\n",
        "  images = []\n",
        "  labels = []\n",
        "  for idx, label in enumerate(uniq_labels):\n",
        "    for file in os.listdir(directory + '/'+label):\n",
        "      filepath = directory +'/'+ label + \"/\" + file\n",
        "      img = cv2.resize(cv2.imread(filepath),(50,50))\n",
        "      images.append(img)\n",
        "      labels.append(idx)\n",
        "  images = np.asarray(images)\n",
        "  labels = np.asarray(labels)\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Coho--Cq9nIa"
      },
      "outputs": [],
      "source": [
        "#display_images function to show examples\n",
        "def display_images(x_data,y_data, title, display_label = True):\n",
        "    x, y = x_data,y_data\n",
        "    fig, axes = plt.subplots(5, 8, figsize = (18, 5))\n",
        "    fig.subplots_adjust(hspace = 0.5, wspace = 0.5)\n",
        "    fig.suptitle(title, fontsize = 18)\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(cv2.cvtColor(x[i], cv2.COLOR_BGR2RGB))\n",
        "        if display_label:\n",
        "            ax.set_xlabel(uniq_labels[y[i]])\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkCfRBb09q52",
        "outputId": "79824b53-0c76-4064-d609-dd02de86df4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbw9uyA_9wUc",
        "outputId": "924a31c9-8c0e-44c5-bf40-a9d41744d515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55501, 50, 50, 3) (55501,)\n"
          ]
        }
      ],
      "source": [
        "#loading_dataset into X_pre and Y_pre\n",
        "data_dir = '/content/drive/My Drive/Gesture Image Data'\n",
        "uniq_labels = sorted(os.listdir(data_dir))\n",
        "X_pre, Y_pre = load_dataset(data_dir)\n",
        "print(X_pre.shape, Y_pre.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiMcZMyGOcO-"
      },
      "outputs": [],
      "source": [
        "#spliting dataset into 80% train, 10% validation and 10% test data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_pre, Y_pre, test_size = 0.8)\n",
        "X_test, X_eval, Y_test, Y_eval = train_test_split(X_test, Y_test, test_size = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quSt0nEPOjgc",
        "outputId": "bbeefd87-0813-49b2-f4e9-50facf213d5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images shape (11100, 50, 50, 3) (11100,)\n",
            "Test images shape (22200, 50, 50, 3) (22200,)\n",
            "Evaluate image shape (22201, 50, 50, 3) (22201,)\n",
            "Printing the labels ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_'] 37\n"
          ]
        }
      ],
      "source": [
        "#print shapes and show examples for each set\n",
        "print(\"Train images shape\",X_train.shape, Y_train.shape)\n",
        "print(\"Test images shape\",X_test.shape, Y_test.shape)\n",
        "print(\"Evaluate image shape\",X_eval.shape, Y_eval.shape)\n",
        "print(\"Printing the labels\",uniq_labels, len(uniq_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ifyjn2XgPagQ"
      },
      "outputs": [],
      "source": [
        "# converting Y_tes and Y_train to One hot vectors using to_categorical\n",
        "# example of one hot => '1' is represented as [0. 1. 0. . . . . 0.]\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_test = to_categorical(Y_test)\n",
        "Y_eval = to_categorical(Y_eval)\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test/ 255.\n",
        "X_eval = X_eval/ 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPBX3s0bPdqA",
        "outputId": "d966e40c-c0b9-4932-c363-564421b3615d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# building our model\n",
        "# Define input shape here\n",
        "input_shape = (50, 50, 3)\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=input_shape), # explicitly define input shape\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation ='relu'), # input_shape removed from here\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation ='relu'),\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation ='relu'),\n",
        "        tf.keras.layers.MaxPool2D((2,2)),\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation ='relu'),\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation ='relu'),\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation ='relu'),\n",
        "        tf.keras.layers.MaxPool2D((2,2)),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation ='relu'),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation ='relu'),\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation ='relu'),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(37, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3gLDrDTPhP7"
      },
      "outputs": [],
      "source": [
        "#compiling the model\n",
        "#default batch size 32\n",
        "#default learning rate is 0.001\n",
        "model.compile(optimizer = 'adam',\n",
        "               loss = 'categorical_crossentropy',\n",
        "               metrics=['accuracy'],)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snu9SofsPjxQ",
        "outputId": "ba6e00f3-e31c-49f0-ec24-46a988606fec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 323ms/step - accuracy: 0.4206 - loss: 2.0288 - val_accuracy: 0.9460 - val_loss: 0.1704\n",
            "Epoch 2/5\n",
            "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 319ms/step - accuracy: 0.9443 - loss: 0.1790 - val_accuracy: 0.9831 - val_loss: 0.0517\n",
            "Epoch 3/5\n",
            "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 303ms/step - accuracy: 0.9738 - loss: 0.0807 - val_accuracy: 0.9906 - val_loss: 0.0319\n",
            "Epoch 4/5\n",
            "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 319ms/step - accuracy: 0.9880 - loss: 0.0411 - val_accuracy: 0.9972 - val_loss: 0.0081\n",
            "Epoch 5/5\n",
            "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 308ms/step - accuracy: 0.9892 - loss: 0.0373 - val_accuracy: 0.9227 - val_loss: 0.2526\n"
          ]
        }
      ],
      "source": [
        "#start training(fitting) the data\n",
        "history = model.fit(X_train, Y_train, epochs=5, verbose=1,\n",
        "                validation_data=(X_eval, Y_eval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3j9zlM2Tn9C",
        "outputId": "d37f667e-e0fa-4253-c3a8-1d084f7d93e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 60ms/step - accuracy: 0.9185 - loss: 0.2593\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.25665998458862305, 0.9207206964492798]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#testing\n",
        "model.evaluate(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFg9juFIS7AX",
        "outputId": "53037f41-36c9-43c3-d8ca-7dd92ccfcbed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.10/dist-packages (1.16.1)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.26.4)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.17.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (24.3.25)\n",
            "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "#Export the model to ONNX format\n",
        "!pip install tf2onnx\n",
        "import tf2onnx\n",
        "import onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWZnhk5c45ts",
        "outputId": "520c8b4a-178f-4d12-c437-a8a086fa1e51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'ResNet18.onnx'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float32, name='keras_tensor_15')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 37), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  139519495819808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495824912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495819984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495826320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495821392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495824384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495828608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495829312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495822976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495966384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495965856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495963040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495968144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495962864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495831248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495969200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495970784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495968496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495970608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495970960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495964800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139519495971840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ],
      "source": [
        "# Convert the model to ONNX\n",
        "model.export(\"ResNet18.onnx\",format=\"onnx\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}